{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, imageio, itertools, pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import imageio\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 함수정의\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_crop(x,crop_w=108,crop_h=108,resize_h=64,resize_w=64):\n",
    "    h,w = x.shape[0], x.shape[1]\n",
    "    j = int(round((h-crop_h)/2.))\n",
    "    i = int(round((w-crop_w)/2.))\n",
    "    return resize(x[j:j+crop_h,i:i+crop_w],(resize_h,resize_w),mode='reflect')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class batch_norm(object):\n",
    "    def __init__(self, epsilon=1e-5, momentum = 0.9, name=\"batch_norm\"):\n",
    "        with tf.variable_scope(name):\n",
    "            self.epsilon  = epsilon\n",
    "            self.momentum = momentum\n",
    "            self.name = name\n",
    "\n",
    "    def __call__(self, x, train=True):\n",
    "        return tf.contrib.layers.batch_norm(x,\n",
    "                      decay=self.momentum, \n",
    "                      updates_collections=None,\n",
    "                      epsilon=self.epsilon,\n",
    "                      scale=True,\n",
    "                      is_training=train,\n",
    "                      scope=self.name)\n",
    "\n",
    "def leakyReLU(x,leak=0.2,name='leakyReLU'):\n",
    "    return tf.maximum(x,leak*x)\n",
    "\n",
    "def conv2d(input_, output_dim, \n",
    "       k_h=5, k_w=5, d_h=2, d_w=2, stddev=0.02,\n",
    "       name=\"conv2d\"):\n",
    "        with tf.variable_scope(name):\n",
    "            w = tf.get_variable('w', [k_h, k_w, input_.get_shape()[-1], output_dim],\n",
    "              initializer=tf.truncated_normal_initializer(stddev=stddev))\n",
    "            conv = tf.nn.conv2d(input_, w, strides=[1, d_h, d_w, 1], padding='SAME')\n",
    "\n",
    "            biases = tf.get_variable('biases', [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "            conv = tf.reshape(tf.nn.bias_add(conv, biases), conv.get_shape())\n",
    "\n",
    "        return conv\n",
    "\n",
    "def conv_out_size_same(size, stride):\n",
    "    return int(math.ceil(float(size) / float(stride)))\n",
    "\n",
    "def linear(input_, output_size, scope=None, stddev=0.02, bias_start=0.0, with_w=False):\n",
    "    shape = input_.get_shape().as_list()\n",
    "\n",
    "    with tf.variable_scope(scope or \"Linear\"):\n",
    "        matrix = tf.get_variable(\"Matrix\", [shape[1], output_size], tf.float32,\n",
    "                 tf.random_normal_initializer(stddev=stddev))\n",
    "        bias = tf.get_variable(\"bias\", [output_size],\n",
    "          initializer=tf.constant_initializer(bias_start))\n",
    "    if with_w:\n",
    "        return tf.matmul(input_, matrix) + bias, matrix, bias\n",
    "    else:\n",
    "        return tf.matmul(input_, matrix) + bias\n",
    "\n",
    "def deconv2d(input_, output_shape,\n",
    "        k_h=5, k_w=5, d_h=2, d_w=2, stddev=0.02,\n",
    "        name=\"deconv2d\", with_w=False):\n",
    "    with tf.variable_scope(name):\n",
    "        # filter : [height, width, output_channels, in_channels]\n",
    "        w = tf.get_variable('w', [k_h, k_w, output_shape[-1], input_.get_shape()[-1]],\n",
    "                  initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "    \n",
    "        try:\n",
    "            deconv = tf.nn.conv2d_transpose(input_, w, output_shape=output_shape,\n",
    "                    strides=[1, d_h, d_w, 1])\n",
    "\n",
    "        # Support for verisons of TensorFlow before 0.7.0\n",
    "        except AttributeError:\n",
    "            deconv = tf.nn.deconv2d(input_, w, output_shape=output_shape,\n",
    "                    strides=[1, d_h, d_w, 1])\n",
    "\n",
    "        biases = tf.get_variable('biases', [output_shape[-1]], initializer=tf.constant_initializer(0.0))\n",
    "        deconv = tf.reshape(tf.nn.bias_add(deconv, biases), deconv.get_shape())\n",
    "\n",
    "        if with_w:\n",
    "            return deconv, w, biases\n",
    "        else:\n",
    "            return deconv\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(object):\n",
    "    def __init__(self,sess,input_height=64,input_width=64,batch_size=64,\n",
    "                 output_height=64,output_width=64,z_dim=100,gf_dim=64,df_dim=64,\n",
    "                 dfc_dim=1024,gfc_dim=1024,color_dim=3):\n",
    "        '''\n",
    "        \n",
    "        Args:\n",
    "            sess : Tensorflow session\n",
    "            batch_size : The size of batch.\n",
    "            z_dim = Dimension of dim for z\n",
    "            gf_dim = Dimension of generator filters in first conv layer\n",
    "            df_dim = Dimension of discriminator filters in frist conv layer\n",
    "            gfc_dim = Dimension of generator units for fully connected layer\n",
    "            dfc_dim = Dimension of discriminaotr units for fully connected layer\n",
    "            color_dim = image color. For grayscale input, set to 1.\n",
    "        '''\n",
    "        self.sess = sess\n",
    "        self.batch_size = batch_size\n",
    "        self.z_dim=z_dim\n",
    "        self.input_height = input_height\n",
    "        self.input_width = input_width\n",
    "        self.output_height = output_height\n",
    "        self.output_width = output_width\n",
    "        \n",
    "        self.gf_dim = gf_dim\n",
    "        self.df_dim = df_dim\n",
    "        \n",
    "        self.gfc_dim = gfc_dim\n",
    "        self.dfc_dim = dfc_dim\n",
    "        self.color_dim=color_dim\n",
    "        # batch normalization : deals with poor initialization helps gradient flow\n",
    "        self.d_bn1 = batch_norm(name = 'd_bn1') \n",
    "        self.d_bn2 = batch_norm(name = 'd_bn2')\n",
    "        self.d_bn3 = batch_norm(name = 'd_bn3')\n",
    "        \n",
    "        self.g_bn0 = batch_norm(name = 'g_bn0')\n",
    "        self.g_bn1 = batch_norm(name = 'g_bn1')\n",
    "        self.g_bn2 = batch_norm(name = 'g_bn2')\n",
    "        self.g_bn3 = batch_norm(name = 'g_bn3')\n",
    "    \n",
    "    def build_model(self):    \n",
    "        \n",
    "        self.input_x = tf.placeholder(\n",
    "        tf.float32,[self.batch_size,self.input_height,self.input_width,self.color_dim],name='real_images')\n",
    "        \n",
    "        self.z = tf.placeholder(\n",
    "        tf.float32,[None,self.z_dim],name='f')\n",
    "        \n",
    "        self.G = self.generator(self.z)\n",
    "        self.D, self.D_logits = self.discriminator(self.input_x,reuse=False)\n",
    "        self.D_, self.D_logits_ = self.discriminator(self.G,reuse=True)\n",
    "        \n",
    "        self.d_loss_real = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=self.D_logits,labels = tf.ones_like(self.D)))\n",
    "        \n",
    "        self.d_loss_fake = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=self.D_logits_,labels = tf.zeros_like(self.D)))\n",
    "        \n",
    "        self.g_loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=self.D_logits_,labels = tf.ones_like(self.D)))\n",
    "\n",
    "        self.d_loss = self.d_loss_real + self.d_loss_fake\n",
    "        \n",
    "        t_vars = tf.trainable_variables()\n",
    "        \n",
    "        self.d_vars = [var for var in t_vars if 'd_' in var.name]\n",
    "        self.g_vars = [var for var in t_vars if 'g_' in var.name]\n",
    "        \n",
    "    \n",
    "    def train(self,data,epoches,learning_rate,beta1):\n",
    "        self.d_optim = tf.train.AdamOptimizer(learning_rate,beta1 = beta1).minimize(self.d_loss,var_list=self.d_vars)\n",
    "        self.g_optim = tf.train.AdamOptimizer(learning_rate,beta1 = beta1).minimize(self.g_loss,var_list=self.g_vars)\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "        \n",
    "        self.data = data\n",
    "        sample_z = np.random.uniform(-1,1,size=(self.batch_size,self.z_dim))\n",
    "        \n",
    "        # results save folder\n",
    "        if not os.path.isdir(\"result\"):\n",
    "            os.mkdir('result')\n",
    "        \n",
    "        iter_per_epoch = len(self.data)//self.batch_size\n",
    "        counter=1\n",
    "        self.train_hist={}\n",
    "        self.train_hist['D_losses'] = []\n",
    "        self.train_hist['G_losses'] = []\n",
    "        self.train_hist['per_epoch_ptimes'] = []\n",
    "        self.train_hist['epoch'] = []\n",
    "        \n",
    "        \n",
    "        for epoch in range(epoches):\n",
    "            start_time=time.time()\n",
    "            for idx in range(iter_per_epoch):\n",
    "                batch_images = self.data[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "                \n",
    "                batch_z = np.random.uniform(-1,1,[self.batch_size,self.z_dim]).astype(np.float32)\n",
    "\n",
    "                # update D network\n",
    "                _,d_losses= self.sess.run([self.d_optim,self.d_loss],feed_dict={self.input_x:batch_images,self.z:batch_z})\n",
    "        \n",
    "                # update G network\n",
    "                _= self.sess.run(self.g_optim,feed_dict={self.z:batch_z})\n",
    "                # twice update G network\n",
    "                _,g_losses = self.sess.run([self.g_optim,self.g_loss],feed_dict={self.z:batch_z})\n",
    "                \n",
    "                errD_fake = sess.run(self.d_loss_fake,feed_dict={\n",
    "                    self.z : batch_z\n",
    "                })\n",
    "                errD_real = sess.run(self.d_loss_real,feed_dict={\n",
    "                    self.input_x : batch_images\n",
    "                })\n",
    "                errG = sess.run(self.g_loss,feed_dict={\n",
    "                    self.z : batch_z\n",
    "                })\n",
    "            \n",
    "                counter += 1\n",
    "            samples = sess.run(self.G,feed_dict={self.z:sample_z})\n",
    "                    \n",
    "            save_images(samples, image_manifold_size(samples.shape[0]),\n",
    "                    './{}/train_{:02d}_{:04d}.png'.format('./result', epoch, idx))\n",
    "                                       \n",
    "            print(\"Epoch: [%2d] [%4d/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f\" \\\n",
    "                              % (epoch, idx,  iter_per_epoch,\n",
    "                                time.time() - start_time, errD_fake+errD_real, errG))\n",
    "            self.train_hist['D_losses'].append(d_losses)\n",
    "            self.train_hist['G_losses'].append(g_losses)\n",
    "            self.train_hist['per_epoch_ptimes'].append(time.time()-start_time)\n",
    "            self.train_hist['epoch'].append(epoch)\n",
    "        \n",
    "        \n",
    "    def discriminator(self,image,reuse=False):\n",
    "        with tf.variable_scope('discriminator') as scope:\n",
    "            # 나중에 fake image도 들어가기 때문에 \n",
    "            if reuse:\n",
    "                scope.reuse_variables()\n",
    "                \n",
    "            h0 = leakyReLU(conv2d(image,self.df_dim,name='d_h0_conv'))\n",
    "            h1 = leakyReLU(self.d_bn1(conv2d(h0,self.df_dim*2,name='d_h1_conv')))\n",
    "            h2 = leakyReLU(self.d_bn2(conv2d(h1,self.df_dim*4,name='d_h2_conv')))\n",
    "            h3 = leakyReLU(self.d_bn3(conv2d(h2,self.df_dim*8,name='d_h3_conv')))\n",
    "            h4 = linear(tf.reshape(h3,[self.batch_size,-1]),1,'d_h4_lin')\n",
    "        \n",
    "        return tf.nn.sigmoid(h4), h4\n",
    "\n",
    "    def generator(self,z):\n",
    "        with tf.variable_scope('generator'):\n",
    "            \n",
    "            s_h, s_w = self.output_height, self.output_width\n",
    "            s_h2, s_w2 = conv_out_size_same(s_h,2),conv_out_size_same(s_w,2)\n",
    "            s_h4, s_w4 = conv_out_size_same(s_h2,2),conv_out_size_same(s_w2,2)\n",
    "            s_h8, s_w8 = conv_out_size_same(s_h4,2),conv_out_size_same(s_w4,2)\n",
    "            s_h16, s_w16 = conv_out_size_same(s_h8,2),conv_out_size_same(s_w8,2)\n",
    "            \n",
    "            # project 'z' and reshape\n",
    "            self.z_, self.h0_w,self.h0_b = linear(\n",
    "            z, self.gf_dim*8*s_h16*s_w16,'g_h0_lin',with_w=True)\n",
    "            \n",
    "            self.h0 = tf.reshape(\n",
    "            self.z_,[-1,s_h16,s_w16,self.gf_dim*8])\n",
    "            h0 = tf.nn.relu(self.g_bn0(self.h0))\n",
    "            \n",
    "            self.h1, self.h1_w, self.h1_b = deconv2d(\n",
    "            h0,[self.batch_size,s_h8,s_w8,self.gf_dim*4],name='g_h1',with_w=True)\n",
    "            h1 = tf.nn.relu(self.g_bn1(self.h1))\n",
    "            \n",
    "            self.h2, self.h2_w, self.h2_b = deconv2d(\n",
    "            h1,[self.batch_size,s_h4,s_w4,self.gf_dim*2],name='g_h2',with_w=True)\n",
    "            h2 = tf.nn.relu(self.g_bn2(self.h2))\n",
    "            \n",
    "            self.h3, self.h3_w, self.h3_b = deconv2d(\n",
    "            h2,[self.batch_size,s_h2,s_w2,self.gf_dim*1],name='g_h3',with_w=True)\n",
    "            h3 = tf.nn.relu(self.g_bn3(self.h3))\n",
    "            \n",
    "            self.h4, self.h4_w, self.h4_b = deconv2d(\n",
    "            h3,[self.batch_size,s_h,s_w,self.color_dim],name='g_h4',with_w=True)\n",
    "            \n",
    "            return tf.nn.tanh(self.h4)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting a directory\n",
    "data_dir = '/home/snu/study/GAN/DCGAN/DCGAN-tensorflow/data/celebA'\n",
    "\n",
    "# data load\n",
    "train_load = io.ImageCollection(data_dir + '/*.jpg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = train_load[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = np.array([center_crop(img) for img in train_load[0:100000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 하이퍼 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0002\n",
    "epoch=400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    dcgan = DCGAN(sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dcgan.train(data_x,learning_rate=0.0002,epoches=epoch,beta1=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 애니메이션 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting a directory\n",
    "result_dir = './celebA_result'\n",
    "\n",
    "# data load\n",
    "result_load = io.ImageCollection(result_dir + '/*.png')\n",
    "\n",
    "images=[]\n",
    "# image들을 gif파일로 저장\n",
    "for result in result_load:\n",
    "        images.append(result)\n",
    "\n",
    "imageio.mimsave('generation_animation.gif',images,fps=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
