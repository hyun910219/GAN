{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as v_utils\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.Scale(size=100),\n",
    "                      transforms.CenterCrop(64),\n",
    "                       transforms.ToTensor()])\n",
    "\n",
    "trainset = dset.ImageFolder(root='C:/Users/NHNEnt/Downloads/img_align_celeba',transform=trans)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,shuffle=True, num_workers=0,drop_last=True)\n",
    "\n",
    "data_length = trainset.__len__()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deconv(ch_in,ch_out,k_size=4,stride=2,pad=1,bn=True):\n",
    "    layers = []\n",
    "    layers.append(nn.ConvTranspose2d(ch_in,ch_out,k_size,stride,padding=pad))\n",
    "    if bn:\n",
    "        layers.append(nn.BatchNorm2d(ch_out))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def conv(ch_in, ch_out, k_size, stride, pad=1, bn=True):\n",
    "    layers = []\n",
    "    layers.append(nn.Conv2d(ch_in,ch_out,k_size,stride,padding=pad))\n",
    "    if bn:\n",
    "        layers.append(nn.BatchNorm2d(ch_out))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class G(nn.Module):\n",
    "    def __init__(self,dim_z=100,input_size=64,out_dim=128,colch=3,leaky=0.2):\n",
    "        super(G,self).__init__()\n",
    "        \n",
    "        self.dim_z = dim_z\n",
    "        self.input_size = input_size\n",
    "        self.out_dim = out_dim\n",
    "        self.colch = colch\n",
    "        self.leaky = leaky\n",
    "        \n",
    "        self.fc = deconv(dim_z,out_dim*8,int(input_size/16),1,0,bn=False)\n",
    "        self.deconv1 = deconv(out_dim*8,out_dim*4,4)\n",
    "        self.deconv2 = deconv(out_dim*4,out_dim*2,4)\n",
    "        self.deconv3 = deconv(out_dim*2,out_dim,4)\n",
    "        self.deconv4 = deconv(out_dim,colch,4,bn=False)\n",
    "\n",
    "        \n",
    "    def forward(self,z):\n",
    "        z = z.view(z.size(0),z.size(1),1,1)\n",
    "        out = self.fc(z)\n",
    "        out = F.leaky_relu(self.deconv1(out),self.leaky )\n",
    "        out = F.leaky_relu(self.deconv2(out),self.leaky )\n",
    "        out = F.leaky_relu(self.deconv3(out),self.leaky )\n",
    "        out = F.tanh(self.deconv4(out))\n",
    "        return out\n",
    "        \n",
    "class D(nn.Module):\n",
    "    def __init__(self,input_size=64,conv_dim=128, colch=3):\n",
    "        super(D,self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.colch = colch\n",
    "        self.conv_dim = conv_dim\n",
    "        \n",
    "        self.conv1 = conv(self.colch,conv_dim,4,2,bn=False)\n",
    "        self.conv2 = conv(conv_dim,conv_dim*2,4,2)\n",
    "        self.conv3 = conv(conv_dim*2,conv_dim*4,4,2)\n",
    "        self.conv4 = conv(conv_dim*4,conv_dim*8,4,2)\n",
    "        self.fc = conv(conv_dim*8,1,4,1,0,bn=False)\n",
    "        self.sigm = nn.Sigmoid()\n",
    "                    \n",
    "    def forward(self,x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.relu(self.conv3(out))\n",
    "        out = F.relu(self.conv4(out))\n",
    "        out = self.fc(out)\n",
    "        out = self.sigm(out).squeeze()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DCGAN(object):\n",
    "    def __init__(self,input_size=64,dim_z=100,colch=3,leaky=0.2,\n",
    "                end_g_dim=64,start_d_dim=64):\n",
    "        \n",
    "        self.input_size= input_size\n",
    "        self.dim_z = dim_z\n",
    "        self.colch = colch\n",
    "        self.leaky = leaky\n",
    "        self.end_g_dim = end_g_dim\n",
    "        self.start_d_dim = start_d_dim\n",
    "        \n",
    "        self.G = None\n",
    "        self.D = None\n",
    "        self.G_optim = None\n",
    "        self.D_optim = None\n",
    "        self.G_losses = []\n",
    "        self.D_losses = []\n",
    "        self.build_model()\n",
    "        \n",
    "        self.fixed_z = Variable(torch.rand(30,100)).cuda()\n",
    "    def build_model(self):\n",
    "        self.G = G(self.dim_z,self.input_size,self.end_g_dim,self.colch,self.leaky).cuda()\n",
    "        self.D = D(self.input_size,self.start_d_dim, self.colch).cuda()\n",
    "    \n",
    "    def denorm(self, x):\n",
    "        \"\"\"Convert range (-1, 1) to (0, 1)\"\"\"\n",
    "        out = (x + 1) / 2\n",
    "        return out.clamp(0, 1)\n",
    "\n",
    "    def train(self, data, batch_size=128,\n",
    "              epoch=10,lr=0.0002,momentum = 0.5, check_step=100):\n",
    "            \n",
    "        batch_length = data.__len__()\n",
    "        \n",
    "        self.G_optim = torch.optim.SGD(self.G.parameters(),lr=lr,momentum = momentum)\n",
    "        self.D_optim = torch.optim.SGD(self.D.parameters(),lr=lr,momentum = momentum)\n",
    "        \n",
    "        loss_func = nn.BCELoss()\n",
    "        \n",
    "        counter = 0\n",
    "        \n",
    "        if not os.path.isdir(\"./dcgan_result\"):\n",
    "            os.mkdir(\"./dcgan_result\")\n",
    "\n",
    "        for e in range(epoch):\n",
    "            for i,[batch_x,_] in enumerate(data):\n",
    "\n",
    "                batch_x = Variable(batch_x).cuda()\n",
    "                # update D\n",
    "                z = Variable(torch.rand(batch_size,self.dim_z)).cuda()\n",
    "                \n",
    "                self.D_optim.zero_grad()\n",
    "                \n",
    "                G_fake = self.denorm(self.G.forward(z))\n",
    "                D_fake = self.D.forward(G_fake)\n",
    "                D_real = self.D.forward(batch_x)\n",
    "                \n",
    "                D_loss = (torch.sum(loss_func(D_fake,Variable(torch.zeros(batch_size)).cuda()))+\n",
    "                          torch.sum(loss_func(D_real,Variable(torch.ones(batch_size)).cuda())))\n",
    "\n",
    "                D_loss.backward(retain_variables=False) # retain_variables=False : 다른 backward를 위해서              \n",
    "                self.D_optim.step()\n",
    "                \n",
    "                # update G\n",
    "                z = Variable(torch.rand(batch_size,self.dim_z)).cuda()\n",
    "                \n",
    "                self.G_optim.zero_grad()\n",
    "                \n",
    "                G_fake = self.denorm(self.G.forward(z))\n",
    "                D_fake = self.D.forward(G_fake)\n",
    "                \n",
    "                G_loss = torch.sum(loss_func(D_fake,Variable(torch.ones(batch_size)).cuda()))\n",
    "                \n",
    "                G_loss.backward()              \n",
    "                self.G_optim.step()\n",
    "                \n",
    "                counter+=1\n",
    "                if counter % check_step == 0:\n",
    "                    \n",
    "                    self.D_losses.append(D_loss.cpu().data.numpy())\n",
    "                    self.G_losses.append(G_loss.cpu().data.numpy())\n",
    "                    \n",
    "                    print(\"Epoch [%d/%d], Step [%d/%d], D_loss : %.4f, G_loss : %.4f\"%(\n",
    "                      e,epoch,i,batch_length,D_loss.cpu().data.numpy(),G_loss.cpu().data.numpy()))\n",
    "                    \n",
    "                    view = self.denorm(self.G.forward(self.fixed_z))\n",
    "                    v_utils.save_image(view.data[0:25],\"./dcgan_result/gen_{}_{}.png\".format(e,i), nrow=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dcgan = DCGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:92: UserWarning: retain_variables option is deprecated and will be removed in 0.3. Use retain_graph instead.\n",
      "  warnings.warn(\"retain_variables option is deprecated and will be removed in 0.3. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100], Step [99/1582], D_loss : 0.3473, G_loss : 2.0785\n",
      "Epoch [0/100], Step [199/1582], D_loss : 0.3869, G_loss : 1.9724\n",
      "Epoch [0/100], Step [299/1582], D_loss : 0.7200, G_loss : 1.5068\n",
      "Epoch [0/100], Step [399/1582], D_loss : 0.8086, G_loss : 1.5355\n",
      "Epoch [0/100], Step [499/1582], D_loss : 0.7496, G_loss : 1.5343\n",
      "Epoch [0/100], Step [599/1582], D_loss : 0.4798, G_loss : 1.7561\n",
      "Epoch [0/100], Step [699/1582], D_loss : 0.3919, G_loss : 1.8978\n",
      "Epoch [0/100], Step [799/1582], D_loss : 0.5753, G_loss : 1.7096\n",
      "Epoch [0/100], Step [899/1582], D_loss : 0.6907, G_loss : 1.6729\n",
      "Epoch [0/100], Step [999/1582], D_loss : 0.4843, G_loss : 1.9273\n",
      "Epoch [0/100], Step [1099/1582], D_loss : 0.5341, G_loss : 1.9187\n",
      "Epoch [0/100], Step [1199/1582], D_loss : 0.5163, G_loss : 2.0403\n",
      "Epoch [0/100], Step [1299/1582], D_loss : 0.4324, G_loss : 2.1354\n",
      "Epoch [0/100], Step [1399/1582], D_loss : 0.2894, G_loss : 2.2495\n",
      "Epoch [0/100], Step [1499/1582], D_loss : 0.4496, G_loss : 2.1117\n",
      "Epoch [1/100], Step [17/1582], D_loss : 0.4151, G_loss : 2.2487\n",
      "Epoch [1/100], Step [117/1582], D_loss : 0.5770, G_loss : 1.9433\n",
      "Epoch [1/100], Step [217/1582], D_loss : 0.3604, G_loss : 2.1987\n",
      "Epoch [1/100], Step [317/1582], D_loss : 0.3702, G_loss : 2.1218\n",
      "Epoch [1/100], Step [417/1582], D_loss : 0.2592, G_loss : 2.4293\n",
      "Epoch [1/100], Step [517/1582], D_loss : 0.2457, G_loss : 2.5665\n",
      "Epoch [1/100], Step [617/1582], D_loss : 0.2792, G_loss : 2.4013\n",
      "Epoch [1/100], Step [717/1582], D_loss : 0.3913, G_loss : 2.3376\n",
      "Epoch [1/100], Step [817/1582], D_loss : 0.3833, G_loss : 2.3766\n",
      "Epoch [1/100], Step [917/1582], D_loss : 0.3297, G_loss : 2.3539\n",
      "Epoch [1/100], Step [1017/1582], D_loss : 0.2364, G_loss : 2.6719\n",
      "Epoch [1/100], Step [1117/1582], D_loss : 0.2457, G_loss : 2.5669\n",
      "Epoch [1/100], Step [1217/1582], D_loss : 0.1657, G_loss : 2.7886\n",
      "Epoch [1/100], Step [1317/1582], D_loss : 0.1898, G_loss : 2.7831\n",
      "Epoch [1/100], Step [1417/1582], D_loss : 0.1895, G_loss : 2.6669\n",
      "Epoch [1/100], Step [1517/1582], D_loss : 0.1981, G_loss : 2.6873\n",
      "Epoch [2/100], Step [35/1582], D_loss : 0.1768, G_loss : 2.9209\n",
      "Epoch [2/100], Step [135/1582], D_loss : 0.1733, G_loss : 2.7149\n",
      "Epoch [2/100], Step [235/1582], D_loss : 0.3311, G_loss : 2.2957\n",
      "Epoch [2/100], Step [335/1582], D_loss : 0.1516, G_loss : 2.9319\n",
      "Epoch [2/100], Step [435/1582], D_loss : 0.1182, G_loss : 3.1950\n",
      "Epoch [2/100], Step [535/1582], D_loss : 0.2524, G_loss : 2.6192\n",
      "Epoch [2/100], Step [635/1582], D_loss : 0.2049, G_loss : 2.8065\n",
      "Epoch [2/100], Step [735/1582], D_loss : 0.2364, G_loss : 2.6023\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 40, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 109, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 109, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 89, in default_collate\n    storage = batch[0].storage()._new_shared(numel)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\storage.py\", line 111, in _new_shared\n    return cls._new_using_filename(size)\nRuntimeError: Couldn't open shared file mapping: <torch_5664_3245707374>, error code: <1455> at D:\\Projects\\pytorch\\torch\\lib\\TH\\THAllocator.c:157\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-5c74e09ff534>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdcgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcheck_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-97d39c4ec20d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, data, batch_size, epoch, lr, momentum, check_step)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[0mbatch_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[0mnext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[1;31m# Python 2 compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Traceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 40, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 109, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 109, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 89, in default_collate\n    storage = batch[0].storage()._new_shared(numel)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\storage.py\", line 111, in _new_shared\n    return cls._new_using_filename(size)\nRuntimeError: Couldn't open shared file mapping: <torch_5664_3245707374>, error code: <1455> at D:\\Projects\\pytorch\\torch\\lib\\TH\\THAllocator.c:157\n"
     ]
    }
   ],
   "source": [
    "dcgan.train(trainloader,epoch=100,check_step=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
