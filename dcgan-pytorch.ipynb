{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as v_utils\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.Scale(size=100),\n",
    "                      transforms.CenterCrop(64),\n",
    "                       transforms.ToTensor()])\n",
    "\n",
    "trainset = dset.ImageFolder(root='/home/snu/study/GAN/DCGAN/DCGAN-tensorflow/data/',transform=trans)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,shuffle=True, num_workers=2,drop_last=True)\n",
    "\n",
    "train_data = iter(trainloader)\n",
    "data_length = trainset.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv(ch_in,ch_out,k_size=4,stride=2,pad=1,bn=True):\n",
    "    layers = []\n",
    "    layers.append(nn.ConvTranspose2d(ch_in,ch_out,k_size,stride,padding=pad))\n",
    "    if bn:\n",
    "        layers.append(nn.BatchNorm2d(ch_out))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def conv(ch_in, ch_out, k_size, stride, pad=1, bn=True):\n",
    "    layers = []\n",
    "    layers.append(nn.Conv2d(ch_in,ch_out,k_size,stride,padding=pad))\n",
    "    if bn:\n",
    "        layers.append(nn.BatchNorm2d(ch_out))\n",
    "    return nn.Sequential(*layers)\n",
    "    \n",
    "def normal_init(m,mean,std):\n",
    "    if isinstance(m,nn.ConvTranspose2d) or isinstance(m,nn.Conv2d):\n",
    "        m.weight.data.normal_(mean,std)\n",
    "        b.bias.data.zero_()\n",
    "        \n",
    "def bn_init(m):\n",
    "    if isinstance(m,nn.BatchNorm2d):\n",
    "        m.weight.data.fill(1)\n",
    "        m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G(nn.Module):\n",
    "    def __init__(self,dim_z=100,input_size=64,out_dim=64,colch=3,leaky=0.2):\n",
    "        super(G,self).__init__()\n",
    "        \n",
    "        self.dim_z = dim_z\n",
    "        self.input_size = input_size\n",
    "        self.out_dim = out_dim\n",
    "        self.colch = colch\n",
    "        self.leaky = leaky\n",
    "        \n",
    "        self.fc = deconv(dim_z,out_dim*8,int(input_size/16),1,0,bn=False)\n",
    "        self.deconv1 = deconv(out_dim*8,out_dim*4,4)\n",
    "        self.deconv2 = deconv(out_dim*4,out_dim*2,4)\n",
    "        self.deconv3 = deconv(out_dim*2,out_dim,4)\n",
    "        self.deconv4 = deconv(out_dim,colch,4,bn=False)\n",
    "        \n",
    "        self.weight_init()\n",
    "        \n",
    "    def weight_init(self,mean=0.,std=0.02):\n",
    "        for m in self._modules:\n",
    "            normal_init(m,mean,std)\n",
    "            bn_init(m)\n",
    "    \n",
    "\n",
    "        \n",
    "    def forward(self,z):\n",
    "            z = z.view(z.size(0),z.size(1),1,1)\n",
    "            out = self.fc(z)\n",
    "            out = F.leaky_relu(self.deconv1(out),self.leaky )\n",
    "            out = F.leaky_relu(self.deconv2(out),self.leaky )\n",
    "            out = F.leaky_relu(self.deconv3(out),self.leaky )\n",
    "            out = F.tanh(self.deconv4(out))\n",
    "            return out\n",
    "        \n",
    "class D(nn.Module):\n",
    "    def __init__(self,input_size=64,conv_dim=64, colch=3):\n",
    "        super(D,self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.colch = colch\n",
    "        self.conv_dim = conv_dim\n",
    "        \n",
    "        self.conv1 = conv(self.colch,conv_dim,4,2,bn=False)\n",
    "        self.conv2 = conv(conv_dim,conv_dim*2,4,2)\n",
    "        self.conv3 = conv(conv_dim*2,conv_dim*4,4,2)\n",
    "        self.conv4 = conv(conv_dim*4,conv_dim*8,4,2)\n",
    "        self.fc = conv(conv_dim*8,1,4,1,0,bn=False)\n",
    "        self.sigm = nn.Sigmoid()\n",
    "        \n",
    "        self.weight_init\n",
    "    def weight_init(self,mean=0.,std=0.02):\n",
    "        for m in self._modules:\n",
    "            normal_init(m,mean,std)\n",
    "            bn_init(m)\n",
    "            \n",
    "    def forward(self,x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.relu(self.conv3(out))\n",
    "        out = F.relu(self.conv4(out))\n",
    "        out = self.fc(out)\n",
    "        out = self.sigm(out).squeeze()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(object):\n",
    "    def __init__(self,input_size=64,dim_z=100,colch=3,leaky=0.2,\n",
    "                end_g_dim=64,start_d_dim=64):\n",
    "        \n",
    "        self.input_size= input_size\n",
    "        self.dim_z = dim_z\n",
    "        self.colch = colch\n",
    "        self.leaky = leaky\n",
    "        self.end_g_dim = end_g_dim\n",
    "        self.start_d_dim = start_d_dim\n",
    "        \n",
    "        self.G = None\n",
    "        self.D = None\n",
    "        self.G_optim = None\n",
    "        self.D_optim = None\n",
    "        \n",
    "        self.build_model()\n",
    "        \n",
    "    def build_model(self):\n",
    "        self.G = G(self.dim_z,self.input_size,self.end_g_dim,self.colch,self.leaky).cuda()\n",
    "        self.D = D(self.input_size,self.start_d_dim, self.colch).cuda()\n",
    "    \n",
    "    def denorm(self, x):\n",
    "        \"\"\"Convert range (-1, 1) to (0, 1)\"\"\"\n",
    "        out = (x + 1) / 2\n",
    "        return out.clamp(0, 1)\n",
    "\n",
    "    def train(self, data, fixed_z, batch_size=128,\n",
    "              epoch=10,lr=0.002,check_step=100):\n",
    "            \n",
    "        batch_length = data.__len__()\n",
    "        \n",
    "        self.G_optim = torch.optim.Adam(self.G.parameters(),lr=lr)\n",
    "        self.D_optim = torch.optim.Adam(self.D.parameters(),lr=lr)\n",
    "        \n",
    "        \n",
    "        loss_func = nn.BCELoss()\n",
    "        \n",
    "       \n",
    "        counter = 0\n",
    "        \n",
    "        if not os.path.isdir(\"./dcgan_result\"):\n",
    "            os.mkdir(\"./dcgan_result\")\n",
    "\n",
    "        for e in range(epoch):\n",
    "            for i in range(batch_length):\n",
    "                \n",
    "                batch_x,_ = data.next()\n",
    "                batch_x = Variable(batch_x).cuda()\n",
    "                # update D\n",
    "                z = Variable(torch.rand(batch_size,self.dim_z)).cuda()\n",
    "                \n",
    "                self.D_optim.zero_grad()\n",
    "                \n",
    "                G_fake = self.denorm(self.G.forward(z))\n",
    "                D_fake = self.D.forward(G_fake)\n",
    "                D_real = self.D.forward(batch_x)\n",
    "                \n",
    "                D_loss = (torch.sum(loss_func(D_fake,Variable(torch.zeros(batch_size)).cuda()))+\n",
    "                          torch.sum(loss_func(D_real,Variable(torch.ones(batch_size)).cuda())))\n",
    "\n",
    "                D_loss.backward(retain_variables=False)\n",
    "                \n",
    "                self.D_optim.step()\n",
    "                \n",
    "                # update G\n",
    "                z = Variable(torch.rand(batch_size,self.dim_z)).cuda()\n",
    "                \n",
    "                self.G_optim.zero_grad()\n",
    "                \n",
    "                G_fake = self.denorm(self.G.forward(z))\n",
    "                D_fake = self.D.forward(G_fake)\n",
    "                \n",
    "                G_loss = torch.sum(loss_func(D_fake,Variable(torch.ones(batch_size)).cuda()))\n",
    "                \n",
    "                G_loss.backward()\n",
    "                \n",
    "                self.G_optim.step()\n",
    "                \n",
    "                counter+=1\n",
    "                if counter % check_step == 0:\n",
    "                    print(\"Epoch [%d/%d], Step [%d/%d], D_loss : %.4f, G_loss : %.4f\"%(\n",
    "                      e,epoch,i,batch_length,D_loss.cpu().data.numpy(),G_loss.cpu().data.numpy()))\n",
    "                    view = self.denorm(self.G.forward(fixed_z))\n",
    "                    v_utils.save_image(view.data[0:25],\"./dcgan_result/gen_{}_{}.png\".format(e,i), nrow=5)\n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_z = Variable(torch.rand(30,100)).cuda()\n",
    "dcgan = DCGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/autograd/__init__.py:92: UserWarning: retain_variables option is deprecated and will be removed in 0.3. Use retain_graph instead.\n",
      "  warnings.warn(\"retain_variables option is deprecated and will be removed in 0.3. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100], Step [499/1582], D_loss : 0.0080, G_loss : 7.4260\n",
      "Epoch [0/100], Step [999/1582], D_loss : 0.0510, G_loss : 8.2566\n",
      "Epoch [0/100], Step [1499/1582], D_loss : 0.0005, G_loss : 9.0580\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-67f02b118b70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdcgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfixed_z\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheck_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-6d765e86c065>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data, fixed_z, batch_size, epoch, lr, check_step)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;31m# update D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dcgan.train(train_data,fixed_z,epoch=100,check_step=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
