{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InfoGAN\n",
    "### Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets\n",
    "\n",
    "### 1. Introduction\n",
    " Unsupervised learning(이하 UL)은 많은 양의 unlabelled data로 부터 가치를 추출하는 general problem이다. 유명한 UL의 framewor로는 represented learning이 있다. represented learning은 unlabelled data를 사용해 중요한 semantic feature들을 쉽게 해독할 수 있는 factor로 표현하는 것을 목표로 한다. representation을 학습하는 방법은 있을 가능성이 크고, 이것은 classification, regression, visualization, reinforcement learning를 포함하는 작업에서 유용하게 쓰일 수 있다..\n",
    " \n",
    " 하지만 UL은 관련있는 downstream task의 training time을 알 수 없기 때문에 ill-posed이지만, data의 중요한 속성을 표현해주는 disentangled representation은 unknown task에 도움을 줄 수 있다. 예를 들어, 얼굴의 데이터셋에서 유용한 disentangled representation은 얼굴의 다양한 속성인 얼굴 윤곽, 헤어스타일, 홍채의 색, 안경유무 그리고 사람마다의 특징을 가질 것이다. disentangled representation은 face recognition, object recognition과 같은 일을 포함하는 일에 도움이 될 것이다. 예를 들어 이미지의 빨간색 필셀 수가 짝수 또는 홀수인지 여부를 결정하는게 목적인 이상한 supervised task에는 해당되지 않는다. 그래서 UL전에 미리 정확한 task를 정할 필요가 있다. \n",
    " \n",
    "(ill-posed problem : 풀고자 하는 해가 관측자료에 지속적으로 민감하게 좌우되는 문제. )\n",
    "\n",
    "UL의 대부분의 연구는 generative modelling으로 이뤄진다. 관찰된 데이터들을 종합하거나 새로 만들어 내기 위해서는 어떤 형태의 이해가 필요하기 때문이다. 그리고 좋지 않은 generative model이 만들어 질 수 있지만, 좋은 generative model은 자동적으로 disentangled representation을 학습할 것이다. 가장 유명한 생성모델로는 VAE와 GAN이 있다.\n",
    " \n",
    " 이 paper에서는 GAN의 objective를 간단하게 바꿔서 해석가능하고 의미있는 representation들을 배울 수 있게 할 것이다. 여기에서는 GAN의 noise variables인 fixed small subset들과 observation의 mutual information을 maximizing하는 것으로 상대적 직관적으로 나타난다.  이 방법은 간단하지만 굉장히 효과적이다. 이것으로 많은 이미지 데이터셋에서 의미가 있는 hidden representation을 발견할 수 있었다. 이런 unsupervised disentangled representation의 효과는 supervised label의 정보를 사용하여 만들어진 이전 작업들과 일치한다. 이러한 결과는 mutual information cost가 추가된 generative modelling은 disentangled representation을 배우는 효과적인 접근임을 보여준다. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Related Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Background : Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Mutual Information for inducing Latent Codes\n",
    "\n",
    " GAN에서는 간단한 noise vector를 input으로 사용한다. 반면에 이런 noise를 사용하는 것에 대한 제한을 두지는 않았다. 결과적으로, noise가 generator에서 매우 복잡하게 사용되어 z의 개별적인 차원이 데이터의 의미론적 기능과 일치하지는 않는다.\n",
    " \n",
    " 그러나, 많은 영역에서 의미있는 변화의 요인으로 자연스럽게 분해된다.예를 들어, MNIST 데이터로 부터 이미지들을 생성할 때, 모델이 자동적으로 숫자를 식별(0-9)을 나타내기 위한 discrete random variable을 할당하고 기울기와 각도를 나타내는 두 개의 continuos random variable을 할당하는 것은 이상적이다. 이런 속성들은 독립적이고 중요하며 supervision 없이도 이러한 concept들을 회복할 수 있다면 유용하다. MNIST digit은 10개의 variable과 2개의 독립된 continuous variable에 의해서 생성되어 간단하게 명시된다.\n",
    " \n",
    " 여기 paper에서는 single unstructured noise vector가 아니라 두 가지로 분리되는 noise vector를 사용한다. \n",
    " - 1. z는 이전의 GAN에서 사용되는 z와 동일하다.\n",
    " - 2. c는 여기에서 latent code라고 불린다. 그리고 데이터 분포의 중요한 feature를 목표로 한다. \n",
    " \n",
    "수학적으로, 구조화된 latent variable의 집합을 $c_1, c_2,...,c_L$로 정의한다. 가장 간단한 형태로, factored distribution : $P(c_1,c_2,...,c_L) = \\prod_{i-1}^{L}P(c_i).$으로 정의한다. 간단한 표기를 위해서, 모든 $c_i$를 concatenation한것을 $c$라고 표기한다.\n",
    "\n",
    "여기에서 unsupervised로 latent factor를 찾는 방법을 제안한다. : generator network에 noise z와 latent code c를 input으로 사용한다. 그래서 generator는 $G(z,c)$의 형태가 된다. 하지만, standard GAN에서는 generator는 $P_G(x\\mid c) = P_G(x)$를 만족하는 답을 찾음으로써 latent code $c$는 무시된다. 이런 문제를 해결하기 위해서, information-theoretic regularization을 제안한다. : latent codes $c$와 generator distribution G(z,c)가 높은 mutual information을 있을 것이다. 그래서 $I(c;G(z,c))$는 높을 것이다.\n",
    "\n",
    "$$\n",
    "I(X;Y) = H(X) - H(X\\mid Y) = H(Y) - H(Y \\mid X)                  \n",
    "$$\n",
    "\n",
    "위의 정의는 다음과 같은 직관적인 해석을 가진다. $I(X;Y)$는 $Y$가 관측되었을 때. $X$의 불확실성의 사라짐을 나타낸다. 만약 $X$와 $Y$가 독립이라면, 한 변수가 다른 변수의 어떠한 부분도 표현할 수 없기 때문에 $I(X;Y)=0$이다. 반대로, 만약에 $X$와 $Y$가 비슷할 때 높은 값을 가진다. 이런 이해는 cost를 공식화하는데 간단하게 만든다. : $x \\sim   P_G(x)$가 주어졌을 때, $P_G(c \\mid x)$가 small entropy를 가지게 만드는 cost\n",
    "\n",
    "다른 말로 하면, latent code c의 정보가 generation process에서 사라지지 않는다. 그래서 여기에서는 다음과 같은 information-regularized를 풀 수 있는 minimax game을 제안한다.\n",
    "\n",
    "$$\n",
    "\\underset{G}{min}\\underset{D}{max}V_I(D,G) = V(D,G) - \\lambda I(c;G(z,c))\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Variational Mutual Information Maximization\n",
    "\n",
    "실제로 mutual information term $I(c;G(z,c))$는 posterior $P(c\\mid x)$를 필요로하기 때문에, 직접적으로 maximize하기 어렵다. 그래서 $P(c\\mid x)$를 근사하는 distribution인 $Q(c \\mid x)$를 정의하여 아래와 같은 lower bound를 얻을 수 있다.\n",
    "\n",
    "$\n",
    "I(c;G(z,c)) = H(c) - H(c \\mid G(z,c))\n",
    "$\n",
    "\n",
    "$\n",
    " \\qquad\\qquad= E_{x \\sim G(z,c)}[E_{\\acute{c} \\sim P(c \\mid x)}[log P(\\acute{c} \\mid x)] + H(c)\n",
    "$\n",
    "\n",
    "$\n",
    "\\qquad\\qquad= E_{x \\sim G(z,c)}[\\underline{E_{\\acute{c} \\sim P(c \\mid x)}[log P(\\acute{c} \\mid x)   - logQ(\\acute c \\mid x) }+log Q(\\acute c \\mid x)]]+ H(c)\n",
    "$\n",
    "\n",
    "$\n",
    "\\qquad\\qquad= E_{x \\sim G(z,c)}[\\underset{\\geq 0}{\\underbrace{D_{KL}(P(\\cdot \\mid x)\\parallel Q(\\cdot \\mid x))}}+E_{\\acute{c} \n",
    "\\sim P(c \\mid x)}[log Q(\\acute c \\mid x)]]+ H(c) \\qquad\\qquad (4)\n",
    "$\n",
    "\n",
    "$\n",
    "\\qquad\\qquad\\geq E_{x \\sim G(z,c)}[E_{\\acute{c} \\sim P(c \\mid x)}[log Q(\\acute{c} \\mid x)]] + H(c)\n",
    "$\n",
    "\n",
    " lower bounding mutual information의 방법은 Variational Information Maximization으로 잘 알려져있다. 추가적으로 여기에서 latent code의 entropy인 $H(c)$는 일반적 분포일 경우에 최적화가 가능하지만 간단하게 만들기 위해서 상수로 설정한다. 지금까지 posterior인 $P(c \\mid x)$를 직접적으로 계산하지 않고 lower bound에 의해서 문제를 해결할려한다. 하지만 여전히 하한선의 inner expectation에서 posterior로 부터 추출을 해야할 필요가 남아있다. 다음에는 간단한 lemma로 부터, posterior로 부터 추출할 필요가 없게할 것이다.\n",
    "\n",
    "$\\mathbf{Lemma 5.1}$\n",
    "\n",
    "For random variables $X, Y$ and $function \\; f(x,y)$ under suitable regularity conditions: \n",
    "$$\n",
    "E_{x \\sim X, y \\sim Y|x}[f(x,y)] = = E_{x \\sim X,y \\sim Y|x, \\acute{x} \\sim X|y}[f(\\acute{x},y)]\n",
    "$$\n",
    "$ \\mathbf{proof}$\n",
    "\n",
    "$\n",
    "E_{x \\sim X, y \\sim Y|x}[f(x,y)] = \\int_{x}P(x)\\int_{y} P(y|x)f(x,y)\\; dydx \n",
    "$\n",
    "\n",
    "$\n",
    "\\qquad\\qquad\\qquad = \\int_{x}\\int_{y}P(x,y)f(x,y)\\;dydx \\quad (Bayes\\,rule)\n",
    "$\n",
    "\n",
    "$\n",
    "\\qquad\\qquad\\qquad= \\int_{y}\\int_{x}P(x,y)f(x,y)\\;dxdy \n",
    "$\n",
    "\n",
    "$\n",
    "\\qquad\\qquad\\qquad = \\int_{y}[\\int_{x}P(x,y)f(x,y)\\;dx\\underset{=1}{\\underline{\\int_{\\acute{x}}P(\\acute{x}|y)\\;d\\acute{x}}}\\,]\\,dy \\quad (\\acute{x} \\sim X) \n",
    "$\n",
    "\n",
    "$\n",
    " \\qquad\\qquad\\qquad= \\int_{y}[\\int_{\\acute{x}}P(\\acute{x},y)f(\\acute{x},y)\\;d\\acute{x}\\int_{x}P(x|y)dx]dy \\quad (x\\,changes\\, \\acute{x}) \n",
    "$\n",
    "\n",
    "$\n",
    "\\qquad\\qquad\\qquad  = \\int_{y}[\\int_{\\acute{x}}P(\\acute{x},y)f(\\acute{x},y)\\;d\\acute{x}\\int_{x}P(y|x)\\frac{P(x)}{P(y)}dx]dy \\quad (bayes rule) \n",
    "$\n",
    "\n",
    "$\n",
    "\\qquad\\qquad\\qquad  = \\int_{x}P(x)\\int_{y}P(y|x)\\int_{\\acute{x}}P(\\acute{x}|y)f(\\acute{x},y)\\;d\\acute{x}dydx\n",
    "$\n",
    "\n",
    "$\n",
    "\\qquad\\qquad\\qquad  = E_{x \\sim X,y \\sim Y|x, \\acute{x} \\sim X|y}[f(\\acute{x},y)]\n",
    "$\n",
    "\n",
    "이 Lemma를 사용하면, mutual information인 $I(c;G(z,c))$의 variational lower bound인 $L_I(G,Q)$는 다음과 같이 정의할 수 있다.\n",
    "\n",
    "$\n",
    "L_I(G,Q) = E_{x \\sim G(z,c)}[E_{\\acute{c} \\sim P(c \\mid x)}[log Q(\\acute{c}|x)]] + H(c) \\qquad\\qquad (5) \\\n",
    "$\n",
    "\n",
    "$\n",
    "\\qquad\\quad =  E_{x \\sim G(z,c),\\acute{c} \\sim P(c \\mid x)}[log Q(\\acute{c}|x)] + H(c)\n",
    "$\n",
    "\n",
    "$\n",
    "\\qquad\\quad= E_{c \\sim C, x \\sim P_{g}(x|z,c), \\acute{c} \\sim C|x}[log Q(\\acute{c|}x)] + H(c)\n",
    "$\n",
    "\n",
    "$\n",
    "\\qquad\\quad= E_{c \\sim C, x \\sim P_{g}(x|z,c)}[log Q(c|x)] + H(c) \\quad (Lemma\\,5.1)\n",
    "$\n",
    "\n",
    "$\n",
    "\\qquad\\quad = E_{c \\sim C, x \\sim G(z,c)}[log Q(c|x)] + H(c)\n",
    "$\n",
    "\n",
    "$\n",
    " \\qquad\\quad\\leq{I(c;G(z,c))}\n",
    "$\n",
    "\n",
    "이 Lemma를 활용하면 Monte Carlo simulation을 쉽게 근사할 수 있다. 특히 $L_I$은 reparametrization trick을 통해서 $Q$와 $G$를를 최대화 할 수 있다. 그래서 $L_I(G,Q)는 GAN의 훈련 절차를 바꾸지 않으면서 추가할 수 있다. 그래서 이 알고리즘을 Information Maximizing Generative Adversarial Networks (InfoGAN)이라고 한다.\n",
    "\n",
    "(4)번 수식에서는 $Q$가 true distribution인 $P$로 가까워 질수록 lower bound가 tight해진다. :  $E_x [D_{KL}(P(\\cdot | x \\parallel Q(\\cdot | x))]] \\,\\rightarrow \\,0$. \n",
    "\n",
    " 추가적으로 lower bound의 최대값인 $L_I(G,Q) = H(c)$일 때, bound는 tight해지고 mutual information이 최대가 된다. Appendix에서는 다른 해석을 증명하기 위해서 InfoGAN이 어떻게 Wake-Sleep Algorithm과 연결되는지 보인다.\n",
    " \n",
    " 결과적으로, InfoGAN은  variational mutual information의 regularirzation과 hypermarametr인 $\\lambda$를 가지는 다음과 같은 minimax game으로 정의된다.\n",
    " \n",
    " $$\n",
    "\\underset{G}{min}\\underset{D}{max}V_I(D,G) = V(D,G) - \\lambda I(c;G(z,c))\n",
    "$$\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
