{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import torchvision.utils as v_utils\n",
    "import itertools\n",
    "import FashionMnist as FM\n",
    "from skimage import io\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n"
     ]
    }
   ],
   "source": [
    "data_set = FM.FashionMNIST('./FashionMnist_data/raw',train=True,transform=transforms.ToTensor(),\n",
    "                     target_transform=None)\n",
    "\n",
    "data = torch.utils.data.DataLoader(data_set, batch_size=128,shuffle=True,\n",
    "                                          num_workers=0,drop_last=True)\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv(ch_in,ch_out,k_size=4,stride=2,pad=1,bn=True,momentum=0.9):\n",
    "    layers = []\n",
    "    layers.append(nn.ConvTranspose2d(ch_in,ch_out,k_size,stride,padding=pad))\n",
    "    if bn:\n",
    "        layers.append(nn.BatchNorm2d(ch_out,momentum=momentum))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def conv(ch_in, ch_out, k_size=4, stride=2, pad=1, bn=True,momentum=0.9):\n",
    "    layers = []\n",
    "    layers.append(nn.Conv2d(ch_in,ch_out,k_size,stride,padding=pad))\n",
    "    if bn:\n",
    "        layers.append(nn.BatchNorm2d(ch_out,momentum=momentum))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def fullycon(input_size,out_size,bn=True,momentum=0.9):\n",
    "    layers = []\n",
    "    layers.append(nn.Linear(input_size,out_size))\n",
    "    if bn:\n",
    "        layers.append(nn.BatchNorm2d(out_size,momentum=momentum))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def normal_init(m,mean,std):\n",
    "    if isinstance(m,nn.ConvTranspose2d) or isinstance(m,nn.Conv2d):\n",
    "        m.weight.data.normal_(mean,std)\n",
    "        b.bias.data.zero_()\n",
    "        \n",
    "def bn_init(m):\n",
    "    if isinstance(m,nn.BatchNorm2d):\n",
    "        m.weight.data.fill(1)\n",
    "        m.bias.data.zero_()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G(nn.Module):\n",
    "    def __init__(self,dim_z=100, dim_c=10, input_size=28, colch=1,conv_dim=16):\n",
    "        super(G,self).__init__()\n",
    "        \n",
    "        self.dim_z = dim_z\n",
    "        self.dim_c = dim_c\n",
    "        self.input_size = input_size\n",
    "        self.colcn = colch\n",
    "        self.conv_dim = conv_dim\n",
    "        self.start_size = int(input_size/4)\n",
    "        \n",
    "        self.fc1 = fullycon(dim_c+dim_z,1024)\n",
    "        self.fc2 = fullycon(1024,conv_dim*8*(self.start_size**2))\n",
    "        self.deconv1 = deconv(conv_dim*8,conv_dim*2)\n",
    "        self.deconv2 = deconv(conv_dim*2,1,bn=False)\n",
    "        self.weight_init()\n",
    "        \n",
    "    def weight_init(self,mean=0,std=0.02):\n",
    "        for m in self._modules:\n",
    "            normal_init(m,mean,std)\n",
    "            bn_init(m)\n",
    "    \n",
    "    def forward(self,z,c):\n",
    "\n",
    "        zc = Variable(torch.cat([z,c],1)).cuda()\n",
    "        out = F.relu(self.fc1(zc))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = out.view(-1,self.conv_dim*8,\n",
    "                              self.start_size,self.start_size)\n",
    "\n",
    "        out = F.relu(self.deconv1(out))\n",
    "        out = F.tanh(self.deconv2(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D(nn.Module):\n",
    "    def __init__(self,input_size=28,colch=1,conv_dim=16,leaky=0.2):\n",
    "        super(D,self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.colch = colch\n",
    "        self.conv_dim = 16\n",
    "        self.leaky = leaky\n",
    "        \n",
    "        self.conv1 = conv(colch,conv_dim*4,4,2,bn=True) # [batch_size,1,28,28] -> [batch_size,16,14,14]\n",
    "        self.conv2 = conv(conv_dim*4,conv_dim*8,4,2,bn=True) # [batch_size,16,14,14] -> [batch_size,32,7,7]\n",
    "        self.fc1 = fullycon(conv_dim*8*int(input_size/4)**2,1024)\n",
    "        self.fc2 = fullycon(1024,11,bn=False)\n",
    "        self.weight_init()\n",
    "        \n",
    "    def weight_init(self,mean=0,std=0.02):\n",
    "        for m in self._modules:\n",
    "            normal_init(m,mean,std)\n",
    "            bn_init(m)\n",
    "            \n",
    "    def forward(self,x):\n",
    "        out = F.leaky_relu(self.conv1(x),self.leaky)\n",
    "        out = F.leaky_relu(self.conv2(out),self.leaky)\n",
    "        out = out.view(-1,self.conv_dim*8*int(self.input_size/4)**2)      \n",
    "        out = F.leaky_relu(self.fc1(out),self.leaky)     \n",
    "        out = self.fc2(out)\n",
    "        latent = out[:,1:12]\n",
    "        out = F.sigmoid(out[:,0])\n",
    "        return out, latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfoGan():\n",
    "    def __init__(self,input_size=28,dim_z=100,dim_c=10,colch=1,conv_dim=16):\n",
    "        self.input_size = input_size\n",
    "        self.dim_z = dim_z\n",
    "        self.dim_c = dim_c\n",
    "        self.colch = colch\n",
    "        self.conv_dim = conv_dim\n",
    "        \n",
    "        self.G = None\n",
    "        self.D = None\n",
    "        self.G_optim = None\n",
    "        self.D_optim = None\n",
    "        self.Info_optim = None\n",
    "        self.G_losses = []\n",
    "        self.D_losses = []\n",
    "        self.Info_losses = []\n",
    "        \n",
    "        self.build_model()\n",
    "        \n",
    "    def build_model(self):\n",
    "        self.G = G(self.dim_z,self.dim_c,self.input_size,self.colch,self.conv_dim).cuda()\n",
    "        self.D = D(self.input_size,self.colch,self.conv_dim).cuda()\n",
    "        \n",
    "    def train(self, data, batch_size=128, epoch=10, lr=0.0002,check_step=100,\n",
    "             view_size=100):\n",
    "        \n",
    "        batch_length = data.__len__()\n",
    "        \n",
    "        self.G_optim = torch.optim.Adam(self.G.parameters(), lr=lr)\n",
    "        self.D_optim = torch.optim.Adam(self.D.parameters(), lr=lr)\n",
    "        self.Info_optim = torch.optim.Adam(itertools.chain(self.G.parameters(),self.D.parameters()),lr=lr)\n",
    "        \n",
    "        loss_func = nn.BCELoss()\n",
    "        loss_CE = nn.CrossEntropyLoss()\n",
    "        counter=0\n",
    "        self.fixed_z, self.fixed_c = self.test_sample(view_size,self.dim_z,self.dim_c)\n",
    "        \n",
    "        if not os.path.isdir(\"./infogan_result\"):\n",
    "            os.mkdir(\"./infogan_result\")\n",
    "            \n",
    "        for e in range(epoch):\n",
    "            for i,[batch_x,_] in enumerate(data):\n",
    "                \n",
    "                batch_x = Variable(batch_x).cuda()\n",
    "                # update D\n",
    "                z,c = self.noise_sample(batch_size,self.dim_z,self.dim_c)\n",
    "                self.batch_x = batch_x\n",
    "\n",
    "                self.D_optim.zero_grad()\n",
    "                \n",
    "                G_fake = self.denorm(self.G.forward(z,c))\n",
    "                D_fake,L_fake = self.D.forward(G_fake)\n",
    "                D_real,L_real = self.D.forward(batch_x)\n",
    "                \n",
    "                D_loss = (torch.sum(loss_func(D_fake,Variable(torch.zeros(batch_size)).cuda())) + \n",
    "                         torch.sum(loss_func(D_real,Variable(torch.ones(batch_size)).cuda())))\n",
    "                         \n",
    "                D_loss.backward(retain_variables=True)\n",
    "                self.D_optim.step()\n",
    "                \n",
    "                # update G\n",
    "                z,c = self.noise_sample(batch_size,self.dim_z,self.dim_c)\n",
    "                \n",
    "                self.G_optim.zero_grad()\n",
    "                \n",
    "                G_fake = self.denorm(self.G.forward(z,c))\n",
    "                D_fake, L_fake = self.D.forward(G_fake)\n",
    "                \n",
    "                G_loss = torch.sum(loss_func(D_fake,Variable(torch.ones(batch_size)).cuda()))\n",
    "                \n",
    "                G_loss.backward(retain_variables=True)\n",
    "                self.G_optim.step()\n",
    "                \n",
    "                # update infoLoss\n",
    "                self.Info_optim.zero_grad()\n",
    "                self.L = L_fake\n",
    "                self.c = c\n",
    "                \n",
    "                Info_loss = loss_CE(L_fake,Variable(torch.max(c,1)[1]).cuda())\n",
    "                Info_loss.backward()\n",
    "                self.Info_optim.step()\n",
    "                \n",
    "                counter+=1\n",
    "                \n",
    "                if counter % check_step ==0:\n",
    "                    \n",
    "                    self.D_losses.append(D_loss.cpu().data.numpy())\n",
    "                    self.G_losses.append(G_loss.cpu().data.numpy())\n",
    "                    self.Info_losses.append(Info_loss.cpu().data.numpy())\n",
    "                    print(\"Epoch [%d/%d], Step [%d/%d], D_loss : %.4f, G_loss : %.4f\" % \n",
    "                          (e+1,epoch,i+1,batch_length,D_loss.cpu().data.numpy(),G_loss.cpu().data.numpy()))\n",
    "                    view = self.denorm(self.G.forward(self.fixed_z, self.fixed_c))\n",
    "                    v_utils.save_image(view.data,\"./infogan_result/gen_{}_{}.png\".format(e,i),nrow=10)\n",
    "\n",
    "    def noise_sample(self,batch_size,dim_z,dim_c):\n",
    "        idx = np.random.randint(dim_c,size=batch_size)\n",
    "        c = np.zeros([batch_size,dim_c],dtype=np.float32)\n",
    "        c[range(batch_size),idx] = 1.\n",
    "        c = torch.from_numpy(c)\n",
    "        \n",
    "        z = torch.Tensor(batch_size,dim_z).uniform_(-1,1)\n",
    "        return z,c\n",
    "    \n",
    "    def test_sample(self,view_size=100,dim_z=10,dim_c=10):\n",
    "        c = np.zeros([view_size,dim_c],dtype=np.float32)\n",
    "\n",
    "        for i in range(view_size):\n",
    "            for j in range(dim_c):\n",
    "                if i//dim_c ==j:\n",
    "                    c[i,j] = 1.\n",
    "        c = torch.from_numpy(c)\n",
    "        \n",
    "        z = torch.Tensor(view_size,dim_z).uniform_(-1,1)\n",
    "        return z,c\n",
    "        \n",
    "    \n",
    "    def denorm(self, x):\n",
    "        \"\"\"Convert range (-1, 1) to (0, 1)\"\"\"\n",
    "        out = (x + 1) / 2\n",
    "        return out.clamp(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "infogan = InfoGan()\n",
    "\n",
    "infogan.train(data,epoch=50,lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 애니메이션 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting a directory\n",
    "result_dir = './infogan_result'\n",
    "\n",
    "# data load\n",
    "result_load = io.ImageCollection(result_dir + '/*.png')\n",
    "\n",
    "images=[]\n",
    "# image들을 gif파일로 저장\n",
    "for i, result in enumerate(result_load):\n",
    "        if i%5 ==0:\n",
    "            images.append(result)\n",
    "\n",
    "imageio.mimsave('generation_animation.gif',images,fps=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
