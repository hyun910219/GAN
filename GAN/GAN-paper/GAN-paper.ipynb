{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "Generative Adversarial Nets는 2014년 Ian J.Goodfellow에 처음 소개되었다. 그 이후 많은 종류의 GAN들이 나오고 있다. 이 글은 Goodfellow의 처음 제시된 GAN의 paper를 보고 정리한 글이다.\n",
    "\n",
    " 최근에 dropout이나 backpropagation 알고리즘 덕분에 discriminative model 중 하나인 deep learning은 큰 성공을 거두고 있다. 하지만 Deep generative model의 경우에는 MLE(maximum likelihood estimation)와 같이 분포를 추정할 때 사용되는 확률 계산을 근사화하기가 어렵고 generative context에서 piecewise linear units의 이점을 활용하기 어렵기 때문이다. 이런 어려움을 피하는 새로운 generative model estimation 절차를 소개하고자 한다.\n",
    " \n",
    " GAN에서는 discriminative model과 generative model 두 개가 존재한다. discriminative model은 sample이 genereative model에서 생성된 model distribution로 부터 왔는지 아니면 실제 데이터의 data distribution부터 왔는지를 구분하기 위해서 학습된다. generative model은 이 discriminative model에 맞서서 속이기 위해서 학습된다.\n",
    " \n",
    " Paper의 저자인 Ian J.Goodfellow는 GAN을 지폐위조범과 경찰로 비유했다.\n",
    "\n",
    "```\n",
    " 지폐위조범(generative model)은 경찰(discriminative model)을 속이기 위해서 노력하고 반면 경찰은 위조 지폐를 감별하기 위해서 노력한다. 이런 게임의 경쟁은 두 팀의 기술인 위조기술과 감별기술이 모두 향상되고 이것은 실제 지폐와 위조 지폐가 구별할 수 없을 정도에 이르게 될것이다.\n",
    "```\n",
    "\n",
    "  아래 그림을 예제로 간략하게 정리해보면 다음과 같다.\n",
    "<img src=\"./image/gan.png\">\n",
    " 우측 고정은 실제 data에서 뽑은 sample인 x에서는 $D(x)=1$이 되기 위해 노력한다. 그리고 왼쪽 과정은 어떤 noise $x$를 generative model인 G에 input으로 사용한다. 그럼 model로 부터 $x$가 만들어진다. 그러면 discriminative model인 D는 $D(G(z))=0$을 만들기 위해 노력하고 generative model인 G는 $D(G(z))=1$을 만들기 위해 노력한다. 이 과정을 놓고보면 'minimax problem'으로 볼 수 있다.\n",
    "\n",
    "이런 framework는 많은 종류의 model의 training알고리즘과 optimization알고리즘을 만들어 낼 수 있다. 이 paper에서는 random noise를 multilayer perceptrow에 통과시켜 generative model이 sample들을 생성하는 경우를 살펴볼것이다. 우리는 model을 backpropagation과 dropout알고리즘을 사용하여 학습할 수 있다. 그리고 sample은 generative model의 forward propagation의 사용으로 만들어 낼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Related work\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Adversarial nets\n",
    "\n",
    "Adeversarial modeling framework는 generative model과 discriminative model이 multilayer perceptron에 적용하는 것이 간단하다.\n",
    "\n",
    " Data $x$에 대헌 generator's distribution인 $p_g$ 를 배우기 위해서는  우린 prior인 input noise variables $p_z(z)$를 정의해야한다. 이 때 data space에 대한 mapping을 $G(z;{\\theta}_g)$로 나타낸다. 여기서 $G$는 매개변수 ${\\theta}$를 갖는 multilayer perceptron으로 나타내는 미분가능한 함수이다.\n",
    " \n",
    " 그리고 두번쨰 multilayer perceptron인 $D(x;{\\theta}_d)$를 정의한다. $D(x)$는 $x$가 실제 데이터인지 generated 데이터인지를 확률인 하나의 scalar값을 반환한다.\n",
    " \n",
    " 우리는 $D$를 $G$로 부터 온 sample들과 training example을 잘구별하기 위한 train을 한다. 우리는 동시에 $G$를 $log(1-D(G(z)))$를 최소화 하기 위해서 학습한다. 즉, $D$와 $G$는 'two-player minimax game with value function'인 $V(G,D)$를 따른다.\n",
    "\n",
    "<img src=\"./image/gan0.png\">\n",
    "\n",
    "아래 그림은 GAN이 어떻게 작동하는지를 간략하게 보여준다.\n",
    "<img src=\"./image/gan2.png\">\n",
    " 검은 점선이 real data distribution이고 초록색 실선은 generated data distribution이다. 그리고 파란 점선은 $D$가 generated인지 real인지 분류한는 확률 그래프로 상대적으로 위에 있을 경우 real로 아래 있을 경우 generated일 확률이 높은것이라고 이해하면 편하다. 그리고 아래 x와 z선은 각각 x와 z의 domain을 나타내며 화살표는 $x=G(z)$의 mapping이 변형된 sample의 분포인 $p_g$가 어떻게 만들어지는지 보여준다. 즉, 간략하게 noise인 $z$가 $G$에 의해서 변형되어 $p_g$의 분포를 가지는 sample $x$가 만들어지는 과정을 보여준다. (a)에서와 같이 처음에는 $p_g$와 $p_{data}$의 분포는 전혀 다르다. 여기서 $D$가 두 distribution을 잘 구별하기 위해서 학습이되면 (b)에서 파란 점선이 smooth해진다. 다음으로 $G$는 D가 잘 구별하기 어렵게 학습이 되어 (c)와 같이 $p_g$의 분포가 옮겨진다. 이렇게 (b)와 (c)의 과정을 반복적으로 수행한다면 (d)와 같이 $p_g=p_{data}$가 되어 D가 전혀 구별하지 못하는 $D(x)=\\frac{1}{2}$인 상태가 될 것이다.\n",
    " \n",
    "알고리즘은 다음과 같다.\n",
    "\n",
    "<img src=\"./image/gan3.png\">\n",
    "?\n",
    "위의 예제를 봤듯이 training은 iterative하고 numerical하게 수행된다. training의 내부 loop를 수행하여 $D$를 최적화하는 것은 finite dataset에서는 overfitting이 발생할 수 있다. 이 방법 대신에 $D$를 $k$ step 동안 업데이트하고 한 번 $G$를 최적화하는 방법을 사용한다. 즉, optimizing $D$ 조기종료하여 overfitting을 방지한다. 그 결과 $D$는 거의 optimal solution에 근접하지만 $G$는 아주 느리게 변화한다. 이 전략은 SML/PCD trainig이 Markov chain의 sample을 한 번의 학습으로 부터 다음의 학습까지 유지하면서 Marcov chain이 폭발하는 것을 막는 방법과 유사하다.\n",
    "? g를 k step d를 한번 g를 빠르게 학습\n",
    " 실제로, (1)에서는 $G$가 잘 학습하기 위한 충분한 gradient가 제공되지 않는다.초기학습에서 $G$의 성능이 좋지 않을 때, $D$는 $G$가 generated sample이 real sample과 차이가 크기 때문에 generated sample을 거부한다. 즉 $V(G,D)$가 0에 가까워 진다. \n",
    " \n",
    " 이 경우는  $log(1-D(G(z)))$가 포화되어 G에 충분한 gradient가 제공되지 않기 때문에 $G$가 학습이 잘 되지 않을 수 있다. 그래서 $log(1-D(G(z)))$를 minimize하기 위해서 $G$를 학습하는 대신에 $log(D(G(z)))$를 maximize하기 위해서 $G$를 학습할 수 있다. 이 목적함수는 같은 결과를 얻지만 학습초기에 더 강한 gradient를 제공해 문제를 피할 수 있다.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Theoretical Result\n",
    "\n",
    "\n",
    " 이번 section에서는 adversarial net의 theoretical result를 보여준다. 3번 section에서 보여준 결과가 타당하다고 주장하기 위해서는 2가지가 증명되어야 한다.\n",
    "##### Main Theorem\n",
    "1. GAN의 minmax problem의 global optimum이 $p_g=p_{data}$이다.\n",
    "2. 제안된 알고리즘1이 global optimum을 찾을 수 있다.\n",
    "\n",
    "여기서 $p_g$는 $z\\sim p_z$일 때 $G(z)$의 distribution으로 G가 implict하게 정의한다.\n",
    "\n",
    "다음으로 section 4.1에서는 위에 제시한 1번을 보일것이고 4.2에서는 2번을 보이겠다.\n",
    "\n",
    "\n",
    "### 4.1 Global Optimality of  $p_g = p_{data}$\n",
    "\n",
    "우선 어떤 $G$가 제시된 상황에서 optimal discriminator $D$를 고려해보자.\n",
    "\n",
    "***Proportion 1.*** For $G$ fixed,the opimal discriminator $D$ is\n",
    "\n",
    "$$\n",
    "{D}^{*}_G (x)\\:=\\:\\frac{p_{data}(x)}{p_{data}(x)+p_g(x)}\\qquad\\qquad\\qquad\\qquad(2)\n",
    "$$\n",
    "\n",
    "***proof.***  $G$가 제시된 상황에서 $V(G,D)$가 miximize하기 위한 discriminator $D$의 훈련 기준은 다음과 같다.\n",
    "\n",
    "\n",
    "<img src=\"./image/gan4.png\">\n",
    "\n",
    " 여기서 $\\int_{z}p_z(z)\\,\\,log(1-D(g(z)))\\,\\,dz$가 $\\:\\int_{x}p_g(x)\\,\\,log(1-D(x))\\,\\,dx$로 변하게 된다. 간단하게 생각하면 $g(z)$로 만들어진 $x$는 real data인 $x$와 같은 space를 가진다. 즉, $g$가 $g(z)$가 $p_g$를 정의하기 때문에 가능하다.\n",
    "\n",
    "위의 $V(G,D)$를 maxminze하는 $D$를 찾기 위해 $D$로 미분을 한다.이 미분식이 0을 만족하는 $D(x)$일 때 $V(G,D)$는 maximize가 된다.\n",
    "$$\n",
    "\\frac{d(V(G,D)}{dD(x)} = \\frac{p_{data}}{D(x)}+\\frac{p_{g}}{1-D(x)}=0\n",
    "$$\n",
    "\n",
    "즉, $D(x) = \\frac{p_{data}(x)}{p_{data}+p_g}\\:$가 optimal discriminator $D$이다.\n",
    "\n",
    "여기서 $D$에 대한 training 목적은 $P(Y=y|x)$를 추정하기 위한 log likelihood를 최대화한 것으로 해석할 수 있다.여기서 $P(Y=y|x)$은 어떤 sample x(real or generated)가 주어졌을 때 $y=1$(real) 또는 $y=0$(generated)일 조건부 확률을 의미한다.\n",
    "\n",
    "결과적으로 1번식을 풀어주면 다음과 같다.\n",
    "\n",
    "<img src=\"./image/gan5.png\">\n",
    "\n",
    "즉, $C(G)$는 어떤 $G$(또는 $p_g$)가 주어졌을 때의 Optimal D를 사용했을 때, $V(G,D)$를 의미한다. 이것들 풀어서 정리하면 밑의 정리를 만족하게 된다.\n",
    "\n",
    "이제 위의 정리들을 바탕으로 Main Theorem 1.을 증명할 수 있다.\n",
    "\n",
    "**Theorem 1.** The global minimum of the virtual training criterion $C(G)$ is achieved if and only if $p_g\\,=\\,p_{data}$. At that point, $C(G)$ achieves the value $-log\\,4$.\n",
    "\n",
    "***proof.*** $p_g\\,=\\,p_{data}$일 때, $D^{*}_G (x) = \\frac{1}{2}$임을 위의 2번 식을 보면 알 수 있다. 그러면 4번 식에서 $C(G)\\,=\\,log\\,\\frac{1}{2}+log\\,\\frac{1}{2}$이 된다. $C(G)$가 best possible value는 오직 $p_g\\,=\\,p_{data}$일 때만 도달할 수 있고 그 값은 $-log\\,4$인것을 확인하면 된다. 즉, $p_g\\,=\\,p_{data}$일 때, $C(G)\\,=\\,-\n",
    "log\\,4$를 가지는데 $C(G)$의 global minimum값이 $-log\\,4$인 것을 보이면 된다.\n",
    "\n",
    "$$\n",
    "C(G)\\,=\\,V(D^{*}_G,G)는 다음과 같다.\n",
    "$$\n",
    "<img src=\"./image/gan6.png\">\n",
    "\n",
    "여기서 KL은 Kullback-Leibler divergence를 나타내며 식은 다음과 같다.\n",
    "\n",
    "$$\n",
    "D_{KL}(P||Q)\\,=\\,\\sum_{i}P(i)log\\frac{P(i)}{Q(i)}\n",
    "$$\n",
    "\n",
    "KL은 두 분포인 P와 Q가 얼마나 다른지를 수치화한 것이다.\n",
    "\n",
    "여기서 JSD는 Jensen-Shannon divergence를 의미하며 식은 다음과 같다.\n",
    "\n",
    "$$\n",
    "JSD(P||Q)\\,=\\,\\frac{1}{2}D_{KL}(P||M)+\\frac{1}{2}D_{KL}(Q||M)\n",
    "$$\n",
    "\n",
    "그럼 위의 식을 정리해보자.\n",
    "\n",
    "\n",
    "$$\n",
    "C(G)\\,=\\,E_{x\\sim p_{data}}[log\\frac{p_{data}}{p_{data}+p_g}]+\\,E_{x\\sim p_{g}}[log\\frac{p_{data}}{p_{data}+p_g}]\n",
    "$$\n",
    "$$\n",
    "\\qquad = -log4 + E_{x\\sim p_{data}}[log\\frac{2*p_{data}}{p_{data}+p_g}]+\\,E_{x\\sim p_{g}}[log\\frac{2*p_{data}}{p_{data}+p_g}]\n",
    "$$\n",
    "$$\n",
    "\\qquad = -log4 + \\sum_{x\\sim p_{data}}p_{data}(log\\frac{2*p_{data}}{p_{data}+p_g})+\\sum_{x\\sim p_g}[log\\frac{2*p_{data}}{p_{data}+p_g}]\n",
    "$$\n",
    "$$\n",
    "\\qquad = -log4 + KL(p_{data}||\\frac{p_{data}+p_g}{2})+ KL(p_{g}||\\frac{p_{data}+p_g}{2})\n",
    "$$\n",
    "$$\n",
    "\\qquad = -log4 + 2*JSD(p_{data}||p_g)\n",
    "$$\n",
    "\n",
    " 두 distribution의 JSD divergence는 항상 0(두 분포가 같을 때)보다 크거나 같기 때문에, 오직 $p_g\\,=\\,p_{data}$일 때 $C(G)$는 global minimum을 가지고 그 값은 $-log4$이다.\n",
    " \n",
    " \n",
    "### 4.2 Convergence of Algorithm 1\n",
    "\n",
    "이번에는 위에 제시한 Algorithm 1이 global optimum인 $p_g\\,=\\,p_{data}$에 수렴하는지를 보인다.\n",
    "\n",
    "***plus.***  convex function과 subderivative\n",
    "\n",
    " 이후에 증명에서 사용될 convex function과 subderivative에 대해서 알아보자.\n",
    "\n",
    "**convex function**은 볼록함수로 임의의 두 점 x, y와 [0,1] 사이의 값 t에 대해 $f(tx+(1-t)y)\\,<=\\,tf(x)+(1-t)f(y)$가 성립하는 $f$를 가리킨다.\n",
    "\n",
    "**subderivative**는 미분가능하지 않은 함수의 미분을 일반화한것이다. \n",
    "\n",
    "<img src=\"./image/gan7.png\">\n",
    "\n",
    "이 $y=|x|$는 convex하지만 convex인 점에서 미분가능하지 않다.\n",
    "\n",
    "그래서 subderivative를 계산하면 \n",
    "\n",
    "<img src=\"./image/gan9.png\">\n",
    "\n",
    " 여기서 [a.b]은 $x_0$에서 $f$의 모든 subderivative이고 subdifferential이라고 불린다. $f$가 convex이기 때문에 0에서의 subdifferential이 정확하게 하나의 subderivative를 가지면 $f$는 $x_0$에서 미분가능하다. \n",
    " \n",
    " 그리고 convex함수에서 subderivative와 subdifferential는 다음과 같은 성질을 가진다.\n",
    "\n",
    "$$\n",
    "f(x)-f(x_0)\\,\\geq\\,v\\cdot(x-x_0)\n",
    "$$\n",
    "\n",
    "여기서 $v$는 $x_0$에서의 subdifferential을 의미한다. 그리고 convex function에서 subdifferential은 항상 존재한다.\n",
    "\n",
    "\n",
    "***Proportion 2.*** If $G$ and $D$가 충분한 크기와 Algorithm1의 충분한 step이 진행된다면, discriminator $D$는 제시된 $G$에 대하여 optimum에 도달할 것이다. 그리고 $p_g$는 다음의 기준으로 향상되며 그 때 $p_g$는 $p_{data}$에 수렴한다.\n",
    "\n",
    "$$\n",
    "E_{x\\sim p_{data}}[log\\,D^{*}_G(x)] + E_{x\\sim p_{g}}[log\\,(1-D^{*}_G(x))]\n",
    "$$\n",
    "\n",
    "***proof.*** 위의 criterion을 $V(G,D)\\,=\\,U(p_g,D)$는 $p_g$의 function으로 생각해보자. $U(p_g,D)$는 $p_g$에 대해 convex하다. convex function의 supremum의 subderivative는 maximum에 도달한 point에서의 function의 derivate를 포함하고 있다. \n",
    "\n",
    "다른 말로, 만약 $f(x)\\,=\\,sup_{\\alpha \\in A}f_{\\alpha}(x)$ 이고 $f_{\\alpha}(x)$가 모든 $\\alpha$에서 $x$에 대해 convex하다면, $\\beta = argsup_{\\alpha \\in A}f_{\\alpha}(x)$이면 $\\partial f_{\\beta}(x)\\,\\in \\, \\partial f$이다. $v\\,\\in\\,\\partial f_{\\beta}(x_0)$라고 하면 subdifferential의 정의에 따라서\n",
    "\n",
    "\n",
    "$$\n",
    "\\\\(f_{\\beta}(x)\\,\\geq\\,f_{\\beta}(x_0) + v\\cdot(x-x_0)\n",
    "$$\n",
    "\n",
    "이것은 adversial net에서 G가 주어진 상태의 Optimal $D$에서 $p_g$를 gradient descent update를 계산하는것과 동일하다. $sup_{D}U(p_g,D)$는 $p_g$에 대하여 ***Theorem 1.***에서 보여준 unique global optima를 가지는 convex function이다. \n",
    "\n",
    " convex함수의 supremum의 subderivative는 maximum에 도달한 point에서의 function의 derivate를 포함한다. \n",
    "\n",
    "$f(p_g) = sup_{d\\in D}f(p_g)$이고 $f_d(x)$가 모든 $d$에서 $x$는 convex라고 하면 $f(p_g)$가 maximum일 때를 $d=D^{*}$(G가 주어졌을 때 optimal D)라 하면 이 $\\partial f_{D^{*}}\\,\\in\\,\\partial f$(subderitive)에 포함된다. 그러므로 subderitive의 성질\n",
    "\n",
    "$$\n",
    "{(f_{D^{*}}(p_{g1})\\,\\geq\\,f_{D^{*}}(p_{g}) + v\\cdot(p_{g1}-p_g)}\n",
    "$$\n",
    "\n",
    "을 활용하여 $G$를 gradient descent update하면 global minimum에 도달하고 즉, $p_g$가 $p_{data}$로 수렴할 것이다.\n",
    "\n",
    "실제로는 adeversial net은 Multilayer Peceptron를 사용하기 때문에 $G가 parameter space에서 여러개의 critical point를 가지기 때문에 완벽하게 증명이 된것이 아니다. 하지만 GAN은 resonable model로 훌륭한 성능을 보이고 있다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
